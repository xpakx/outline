{"ast":null,"code":"/**\n * marked - a markdown parser\n * Copyright (c) 2011-2022, Christopher Jeffrey. (MIT Licensed)\n * https://github.com/markedjs/marked\n */\n\n/**\n * DO NOT EDIT THIS FILE\n * The code in this file is generated from files in ./src/\n */\nfunction getDefaults() {\n  return {\n    baseUrl: null,\n    breaks: false,\n    extensions: null,\n    gfm: true,\n    headerIds: true,\n    headerPrefix: '',\n    highlight: null,\n    langPrefix: 'language-',\n    mangle: true,\n    pedantic: false,\n    renderer: null,\n    sanitize: false,\n    sanitizer: null,\n    silent: false,\n    smartLists: false,\n    smartypants: false,\n    tokenizer: null,\n    walkTokens: null,\n    xhtml: false\n  };\n}\n\nlet defaults = getDefaults();\n\nfunction changeDefaults(newDefaults) {\n  defaults = newDefaults;\n}\n/**\n * Helpers\n */\n\n\nconst escapeTest = /[&<>\"']/;\nconst escapeReplace = /[&<>\"']/g;\nconst escapeTestNoEncode = /[<>\"']|&(?!#?\\w+;)/;\nconst escapeReplaceNoEncode = /[<>\"']|&(?!#?\\w+;)/g;\nconst escapeReplacements = {\n  '&': '&amp;',\n  '<': '&lt;',\n  '>': '&gt;',\n  '\"': '&quot;',\n  \"'\": '&#39;'\n};\n\nconst getEscapeReplacement = ch => escapeReplacements[ch];\n\nfunction escape(html, encode) {\n  if (encode) {\n    if (escapeTest.test(html)) {\n      return html.replace(escapeReplace, getEscapeReplacement);\n    }\n  } else {\n    if (escapeTestNoEncode.test(html)) {\n      return html.replace(escapeReplaceNoEncode, getEscapeReplacement);\n    }\n  }\n\n  return html;\n}\n\nconst unescapeTest = /&(#(?:\\d+)|(?:#x[0-9A-Fa-f]+)|(?:\\w+));?/ig;\n\nfunction unescape(html) {\n  // explicitly match decimal, hex, and named HTML entities\n  return html.replace(unescapeTest, (_, n) => {\n    n = n.toLowerCase();\n    if (n === 'colon') return ':';\n\n    if (n.charAt(0) === '#') {\n      return n.charAt(1) === 'x' ? String.fromCharCode(parseInt(n.substring(2), 16)) : String.fromCharCode(+n.substring(1));\n    }\n\n    return '';\n  });\n}\n\nconst caret = /(^|[^\\[])\\^/g;\n\nfunction edit(regex, opt) {\n  regex = regex.source || regex;\n  opt = opt || '';\n  const obj = {\n    replace: (name, val) => {\n      val = val.source || val;\n      val = val.replace(caret, '$1');\n      regex = regex.replace(name, val);\n      return obj;\n    },\n    getRegex: () => {\n      return new RegExp(regex, opt);\n    }\n  };\n  return obj;\n}\n\nconst nonWordAndColonTest = /[^\\w:]/g;\nconst originIndependentUrl = /^$|^[a-z][a-z0-9+.-]*:|^[?#]/i;\n\nfunction cleanUrl(sanitize, base, href) {\n  if (sanitize) {\n    let prot;\n\n    try {\n      prot = decodeURIComponent(unescape(href)).replace(nonWordAndColonTest, '').toLowerCase();\n    } catch (e) {\n      return null;\n    }\n\n    if (prot.indexOf('javascript:') === 0 || prot.indexOf('vbscript:') === 0 || prot.indexOf('data:') === 0) {\n      return null;\n    }\n  }\n\n  if (base && !originIndependentUrl.test(href)) {\n    href = resolveUrl(base, href);\n  }\n\n  try {\n    href = encodeURI(href).replace(/%25/g, '%');\n  } catch (e) {\n    return null;\n  }\n\n  return href;\n}\n\nconst baseUrls = {};\nconst justDomain = /^[^:]+:\\/*[^/]*$/;\nconst protocol = /^([^:]+:)[\\s\\S]*$/;\nconst domain = /^([^:]+:\\/*[^/]*)[\\s\\S]*$/;\n\nfunction resolveUrl(base, href) {\n  if (!baseUrls[' ' + base]) {\n    // we can ignore everything in base after the last slash of its path component,\n    // but we might need to add _that_\n    // https://tools.ietf.org/html/rfc3986#section-3\n    if (justDomain.test(base)) {\n      baseUrls[' ' + base] = base + '/';\n    } else {\n      baseUrls[' ' + base] = rtrim(base, '/', true);\n    }\n  }\n\n  base = baseUrls[' ' + base];\n  const relativeBase = base.indexOf(':') === -1;\n\n  if (href.substring(0, 2) === '//') {\n    if (relativeBase) {\n      return href;\n    }\n\n    return base.replace(protocol, '$1') + href;\n  } else if (href.charAt(0) === '/') {\n    if (relativeBase) {\n      return href;\n    }\n\n    return base.replace(domain, '$1') + href;\n  } else {\n    return base + href;\n  }\n}\n\nconst noopTest = {\n  exec: function noopTest() {}\n};\n\nfunction merge(obj) {\n  let i = 1,\n      target,\n      key;\n\n  for (; i < arguments.length; i++) {\n    target = arguments[i];\n\n    for (key in target) {\n      if (Object.prototype.hasOwnProperty.call(target, key)) {\n        obj[key] = target[key];\n      }\n    }\n  }\n\n  return obj;\n}\n\nfunction splitCells(tableRow, count) {\n  // ensure that every cell-delimiting pipe has a space\n  // before it to distinguish it from an escaped pipe\n  const row = tableRow.replace(/\\|/g, (match, offset, str) => {\n    let escaped = false,\n        curr = offset;\n\n    while (--curr >= 0 && str[curr] === '\\\\') escaped = !escaped;\n\n    if (escaped) {\n      // odd number of slashes means | is escaped\n      // so we leave it alone\n      return '|';\n    } else {\n      // add space before unescaped |\n      return ' |';\n    }\n  }),\n        cells = row.split(/ \\|/);\n  let i = 0; // First/last cell in a row cannot be empty if it has no leading/trailing pipe\n\n  if (!cells[0].trim()) {\n    cells.shift();\n  }\n\n  if (cells.length > 0 && !cells[cells.length - 1].trim()) {\n    cells.pop();\n  }\n\n  if (cells.length > count) {\n    cells.splice(count);\n  } else {\n    while (cells.length < count) cells.push('');\n  }\n\n  for (; i < cells.length; i++) {\n    // leading or trailing whitespace is ignored per the gfm spec\n    cells[i] = cells[i].trim().replace(/\\\\\\|/g, '|');\n  }\n\n  return cells;\n} // Remove trailing 'c's. Equivalent to str.replace(/c*$/, '').\n// /c*$/ is vulnerable to REDOS.\n// invert: Remove suffix of non-c chars instead. Default falsey.\n\n\nfunction rtrim(str, c, invert) {\n  const l = str.length;\n\n  if (l === 0) {\n    return '';\n  } // Length of suffix matching the invert condition.\n\n\n  let suffLen = 0; // Step left until we fail to match the invert condition.\n\n  while (suffLen < l) {\n    const currChar = str.charAt(l - suffLen - 1);\n\n    if (currChar === c && !invert) {\n      suffLen++;\n    } else if (currChar !== c && invert) {\n      suffLen++;\n    } else {\n      break;\n    }\n  }\n\n  return str.substr(0, l - suffLen);\n}\n\nfunction findClosingBracket(str, b) {\n  if (str.indexOf(b[1]) === -1) {\n    return -1;\n  }\n\n  const l = str.length;\n  let level = 0,\n      i = 0;\n\n  for (; i < l; i++) {\n    if (str[i] === '\\\\') {\n      i++;\n    } else if (str[i] === b[0]) {\n      level++;\n    } else if (str[i] === b[1]) {\n      level--;\n\n      if (level < 0) {\n        return i;\n      }\n    }\n  }\n\n  return -1;\n}\n\nfunction checkSanitizeDeprecation(opt) {\n  if (opt && opt.sanitize && !opt.silent) {\n    console.warn('marked(): sanitize and sanitizer parameters are deprecated since version 0.7.0, should not be used and will be removed in the future. Read more here: https://marked.js.org/#/USING_ADVANCED.md#options');\n  }\n} // copied from https://stackoverflow.com/a/5450113/806777\n\n\nfunction repeatString(pattern, count) {\n  if (count < 1) {\n    return '';\n  }\n\n  let result = '';\n\n  while (count > 1) {\n    if (count & 1) {\n      result += pattern;\n    }\n\n    count >>= 1;\n    pattern += pattern;\n  }\n\n  return result + pattern;\n}\n\nfunction outputLink(cap, link, raw, lexer) {\n  const href = link.href;\n  const title = link.title ? escape(link.title) : null;\n  const text = cap[1].replace(/\\\\([\\[\\]])/g, '$1');\n\n  if (cap[0].charAt(0) !== '!') {\n    lexer.state.inLink = true;\n    const token = {\n      type: 'link',\n      raw,\n      href,\n      title,\n      text,\n      tokens: lexer.inlineTokens(text, [])\n    };\n    lexer.state.inLink = false;\n    return token;\n  } else {\n    return {\n      type: 'image',\n      raw,\n      href,\n      title,\n      text: escape(text)\n    };\n  }\n}\n\nfunction indentCodeCompensation(raw, text) {\n  const matchIndentToCode = raw.match(/^(\\s+)(?:```)/);\n\n  if (matchIndentToCode === null) {\n    return text;\n  }\n\n  const indentToCode = matchIndentToCode[1];\n  return text.split('\\n').map(node => {\n    const matchIndentInNode = node.match(/^\\s+/);\n\n    if (matchIndentInNode === null) {\n      return node;\n    }\n\n    const [indentInNode] = matchIndentInNode;\n\n    if (indentInNode.length >= indentToCode.length) {\n      return node.slice(indentToCode.length);\n    }\n\n    return node;\n  }).join('\\n');\n}\n/**\n * Tokenizer\n */\n\n\nclass Tokenizer {\n  constructor(options) {\n    this.options = options || defaults;\n  }\n\n  space(src) {\n    const cap = this.rules.block.newline.exec(src);\n\n    if (cap && cap[0].length > 0) {\n      return {\n        type: 'space',\n        raw: cap[0]\n      };\n    }\n  }\n\n  code(src) {\n    const cap = this.rules.block.code.exec(src);\n\n    if (cap) {\n      const text = cap[0].replace(/^ {1,4}/gm, '');\n      return {\n        type: 'code',\n        raw: cap[0],\n        codeBlockStyle: 'indented',\n        text: !this.options.pedantic ? rtrim(text, '\\n') : text\n      };\n    }\n  }\n\n  fences(src) {\n    const cap = this.rules.block.fences.exec(src);\n\n    if (cap) {\n      const raw = cap[0];\n      const text = indentCodeCompensation(raw, cap[3] || '');\n      return {\n        type: 'code',\n        raw,\n        lang: cap[2] ? cap[2].trim() : cap[2],\n        text\n      };\n    }\n  }\n\n  heading(src) {\n    const cap = this.rules.block.heading.exec(src);\n\n    if (cap) {\n      let text = cap[2].trim(); // remove trailing #s\n\n      if (/#$/.test(text)) {\n        const trimmed = rtrim(text, '#');\n\n        if (this.options.pedantic) {\n          text = trimmed.trim();\n        } else if (!trimmed || / $/.test(trimmed)) {\n          // CommonMark requires space before trailing #s\n          text = trimmed.trim();\n        }\n      }\n\n      const token = {\n        type: 'heading',\n        raw: cap[0],\n        depth: cap[1].length,\n        text: text,\n        tokens: []\n      };\n      this.lexer.inline(token.text, token.tokens);\n      return token;\n    }\n  }\n\n  hr(src) {\n    const cap = this.rules.block.hr.exec(src);\n\n    if (cap) {\n      return {\n        type: 'hr',\n        raw: cap[0]\n      };\n    }\n  }\n\n  blockquote(src) {\n    const cap = this.rules.block.blockquote.exec(src);\n\n    if (cap) {\n      const text = cap[0].replace(/^ *> ?/gm, '');\n      return {\n        type: 'blockquote',\n        raw: cap[0],\n        tokens: this.lexer.blockTokens(text, []),\n        text\n      };\n    }\n  }\n\n  list(src) {\n    let cap = this.rules.block.list.exec(src);\n\n    if (cap) {\n      let raw, istask, ischecked, indent, i, blankLine, endsWithBlankLine, line, nextLine, rawLine, itemContents, endEarly;\n      let bull = cap[1].trim();\n      const isordered = bull.length > 1;\n      const list = {\n        type: 'list',\n        raw: '',\n        ordered: isordered,\n        start: isordered ? +bull.slice(0, -1) : '',\n        loose: false,\n        items: []\n      };\n      bull = isordered ? `\\\\d{1,9}\\\\${bull.slice(-1)}` : `\\\\${bull}`;\n\n      if (this.options.pedantic) {\n        bull = isordered ? bull : '[*+-]';\n      } // Get next list item\n\n\n      const itemRegex = new RegExp(`^( {0,3}${bull})((?: [^\\\\n]*)?(?:\\\\n|$))`); // Check if current bullet point can start a new List Item\n\n      while (src) {\n        endEarly = false;\n\n        if (!(cap = itemRegex.exec(src))) {\n          break;\n        }\n\n        if (this.rules.block.hr.test(src)) {\n          // End list if bullet was actually HR (possibly move into itemRegex?)\n          break;\n        }\n\n        raw = cap[0];\n        src = src.substring(raw.length);\n        line = cap[2].split('\\n', 1)[0];\n        nextLine = src.split('\\n', 1)[0];\n\n        if (this.options.pedantic) {\n          indent = 2;\n          itemContents = line.trimLeft();\n        } else {\n          indent = cap[2].search(/[^ ]/); // Find first non-space char\n\n          indent = indent > 4 ? 1 : indent; // Treat indented code blocks (> 4 spaces) as having only 1 indent\n\n          itemContents = line.slice(indent);\n          indent += cap[1].length;\n        }\n\n        blankLine = false;\n\n        if (!line && /^ *$/.test(nextLine)) {\n          // Items begin with at most one blank line\n          raw += nextLine + '\\n';\n          src = src.substring(nextLine.length + 1);\n          endEarly = true;\n        }\n\n        if (!endEarly) {\n          const nextBulletRegex = new RegExp(`^ {0,${Math.min(3, indent - 1)}}(?:[*+-]|\\\\d{1,9}[.)])`); // Check if following lines should be included in List Item\n\n          while (src) {\n            rawLine = src.split('\\n', 1)[0];\n            line = rawLine; // Re-align to follow commonmark nesting rules\n\n            if (this.options.pedantic) {\n              line = line.replace(/^ {1,4}(?=( {4})*[^ ])/g, '  ');\n            } // End list item if found start of new bullet\n\n\n            if (nextBulletRegex.test(line)) {\n              break;\n            }\n\n            if (line.search(/[^ ]/) >= indent || !line.trim()) {\n              // Dedent if possible\n              itemContents += '\\n' + line.slice(indent);\n            } else if (!blankLine) {\n              // Until blank line, item doesn't need indentation\n              itemContents += '\\n' + line;\n            } else {\n              // Otherwise, improper indentation ends this item\n              break;\n            }\n\n            if (!blankLine && !line.trim()) {\n              // Check if current line is blank\n              blankLine = true;\n            }\n\n            raw += rawLine + '\\n';\n            src = src.substring(rawLine.length + 1);\n          }\n        }\n\n        if (!list.loose) {\n          // If the previous item ended with a blank line, the list is loose\n          if (endsWithBlankLine) {\n            list.loose = true;\n          } else if (/\\n *\\n *$/.test(raw)) {\n            endsWithBlankLine = true;\n          }\n        } // Check for task list items\n\n\n        if (this.options.gfm) {\n          istask = /^\\[[ xX]\\] /.exec(itemContents);\n\n          if (istask) {\n            ischecked = istask[0] !== '[ ] ';\n            itemContents = itemContents.replace(/^\\[[ xX]\\] +/, '');\n          }\n        }\n\n        list.items.push({\n          type: 'list_item',\n          raw: raw,\n          task: !!istask,\n          checked: ischecked,\n          loose: false,\n          text: itemContents\n        });\n        list.raw += raw;\n      } // Do not consume newlines at end of final item. Alternatively, make itemRegex *start* with any newlines to simplify/speed up endsWithBlankLine logic\n\n\n      list.items[list.items.length - 1].raw = raw.trimRight();\n      list.items[list.items.length - 1].text = itemContents.trimRight();\n      list.raw = list.raw.trimRight();\n      const l = list.items.length; // Item child tokens handled here at end because we needed to have the final item to trim it first\n\n      for (i = 0; i < l; i++) {\n        this.lexer.state.top = false;\n        list.items[i].tokens = this.lexer.blockTokens(list.items[i].text, []);\n        const spacers = list.items[i].tokens.filter(t => t.type === 'space');\n        const hasMultipleLineBreaks = spacers.every(t => {\n          const chars = t.raw.split('');\n          let lineBreaks = 0;\n\n          for (const char of chars) {\n            if (char === '\\n') {\n              lineBreaks += 1;\n            }\n\n            if (lineBreaks > 1) {\n              return true;\n            }\n          }\n\n          return false;\n        });\n\n        if (!list.loose && spacers.length && hasMultipleLineBreaks) {\n          // Having a single line break doesn't mean a list is loose. A single line break is terminating the last list item\n          list.loose = true;\n          list.items[i].loose = true;\n        }\n      }\n\n      return list;\n    }\n  }\n\n  html(src) {\n    const cap = this.rules.block.html.exec(src);\n\n    if (cap) {\n      const token = {\n        type: 'html',\n        raw: cap[0],\n        pre: !this.options.sanitizer && (cap[1] === 'pre' || cap[1] === 'script' || cap[1] === 'style'),\n        text: cap[0]\n      };\n\n      if (this.options.sanitize) {\n        token.type = 'paragraph';\n        token.text = this.options.sanitizer ? this.options.sanitizer(cap[0]) : escape(cap[0]);\n        token.tokens = [];\n        this.lexer.inline(token.text, token.tokens);\n      }\n\n      return token;\n    }\n  }\n\n  def(src) {\n    const cap = this.rules.block.def.exec(src);\n\n    if (cap) {\n      if (cap[3]) cap[3] = cap[3].substring(1, cap[3].length - 1);\n      const tag = cap[1].toLowerCase().replace(/\\s+/g, ' ');\n      return {\n        type: 'def',\n        tag,\n        raw: cap[0],\n        href: cap[2],\n        title: cap[3]\n      };\n    }\n  }\n\n  table(src) {\n    const cap = this.rules.block.table.exec(src);\n\n    if (cap) {\n      const item = {\n        type: 'table',\n        header: splitCells(cap[1]).map(c => {\n          return {\n            text: c\n          };\n        }),\n        align: cap[2].replace(/^ *|\\| *$/g, '').split(/ *\\| */),\n        rows: cap[3] && cap[3].trim() ? cap[3].replace(/\\n[ \\t]*$/, '').split('\\n') : []\n      };\n\n      if (item.header.length === item.align.length) {\n        item.raw = cap[0];\n        let l = item.align.length;\n        let i, j, k, row;\n\n        for (i = 0; i < l; i++) {\n          if (/^ *-+: *$/.test(item.align[i])) {\n            item.align[i] = 'right';\n          } else if (/^ *:-+: *$/.test(item.align[i])) {\n            item.align[i] = 'center';\n          } else if (/^ *:-+ *$/.test(item.align[i])) {\n            item.align[i] = 'left';\n          } else {\n            item.align[i] = null;\n          }\n        }\n\n        l = item.rows.length;\n\n        for (i = 0; i < l; i++) {\n          item.rows[i] = splitCells(item.rows[i], item.header.length).map(c => {\n            return {\n              text: c\n            };\n          });\n        } // parse child tokens inside headers and cells\n        // header child tokens\n\n\n        l = item.header.length;\n\n        for (j = 0; j < l; j++) {\n          item.header[j].tokens = [];\n          this.lexer.inlineTokens(item.header[j].text, item.header[j].tokens);\n        } // cell child tokens\n\n\n        l = item.rows.length;\n\n        for (j = 0; j < l; j++) {\n          row = item.rows[j];\n\n          for (k = 0; k < row.length; k++) {\n            row[k].tokens = [];\n            this.lexer.inlineTokens(row[k].text, row[k].tokens);\n          }\n        }\n\n        return item;\n      }\n    }\n  }\n\n  lheading(src) {\n    const cap = this.rules.block.lheading.exec(src);\n\n    if (cap) {\n      const token = {\n        type: 'heading',\n        raw: cap[0],\n        depth: cap[2].charAt(0) === '=' ? 1 : 2,\n        text: cap[1],\n        tokens: []\n      };\n      this.lexer.inline(token.text, token.tokens);\n      return token;\n    }\n  }\n\n  paragraph(src) {\n    const cap = this.rules.block.paragraph.exec(src);\n\n    if (cap) {\n      const token = {\n        type: 'paragraph',\n        raw: cap[0],\n        text: cap[1].charAt(cap[1].length - 1) === '\\n' ? cap[1].slice(0, -1) : cap[1],\n        tokens: []\n      };\n      this.lexer.inline(token.text, token.tokens);\n      return token;\n    }\n  }\n\n  text(src) {\n    const cap = this.rules.block.text.exec(src);\n\n    if (cap) {\n      const token = {\n        type: 'text',\n        raw: cap[0],\n        text: cap[0],\n        tokens: []\n      };\n      this.lexer.inline(token.text, token.tokens);\n      return token;\n    }\n  }\n\n  escape(src) {\n    const cap = this.rules.inline.escape.exec(src);\n\n    if (cap) {\n      return {\n        type: 'escape',\n        raw: cap[0],\n        text: escape(cap[1])\n      };\n    }\n  }\n\n  tag(src) {\n    const cap = this.rules.inline.tag.exec(src);\n\n    if (cap) {\n      if (!this.lexer.state.inLink && /^<a /i.test(cap[0])) {\n        this.lexer.state.inLink = true;\n      } else if (this.lexer.state.inLink && /^<\\/a>/i.test(cap[0])) {\n        this.lexer.state.inLink = false;\n      }\n\n      if (!this.lexer.state.inRawBlock && /^<(pre|code|kbd|script)(\\s|>)/i.test(cap[0])) {\n        this.lexer.state.inRawBlock = true;\n      } else if (this.lexer.state.inRawBlock && /^<\\/(pre|code|kbd|script)(\\s|>)/i.test(cap[0])) {\n        this.lexer.state.inRawBlock = false;\n      }\n\n      return {\n        type: this.options.sanitize ? 'text' : 'html',\n        raw: cap[0],\n        inLink: this.lexer.state.inLink,\n        inRawBlock: this.lexer.state.inRawBlock,\n        text: this.options.sanitize ? this.options.sanitizer ? this.options.sanitizer(cap[0]) : escape(cap[0]) : cap[0]\n      };\n    }\n  }\n\n  link(src) {\n    const cap = this.rules.inline.link.exec(src);\n\n    if (cap) {\n      const trimmedUrl = cap[2].trim();\n\n      if (!this.options.pedantic && /^</.test(trimmedUrl)) {\n        // commonmark requires matching angle brackets\n        if (!/>$/.test(trimmedUrl)) {\n          return;\n        } // ending angle bracket cannot be escaped\n\n\n        const rtrimSlash = rtrim(trimmedUrl.slice(0, -1), '\\\\');\n\n        if ((trimmedUrl.length - rtrimSlash.length) % 2 === 0) {\n          return;\n        }\n      } else {\n        // find closing parenthesis\n        const lastParenIndex = findClosingBracket(cap[2], '()');\n\n        if (lastParenIndex > -1) {\n          const start = cap[0].indexOf('!') === 0 ? 5 : 4;\n          const linkLen = start + cap[1].length + lastParenIndex;\n          cap[2] = cap[2].substring(0, lastParenIndex);\n          cap[0] = cap[0].substring(0, linkLen).trim();\n          cap[3] = '';\n        }\n      }\n\n      let href = cap[2];\n      let title = '';\n\n      if (this.options.pedantic) {\n        // split pedantic href and title\n        const link = /^([^'\"]*[^\\s])\\s+(['\"])(.*)\\2/.exec(href);\n\n        if (link) {\n          href = link[1];\n          title = link[3];\n        }\n      } else {\n        title = cap[3] ? cap[3].slice(1, -1) : '';\n      }\n\n      href = href.trim();\n\n      if (/^</.test(href)) {\n        if (this.options.pedantic && !/>$/.test(trimmedUrl)) {\n          // pedantic allows starting angle bracket without ending angle bracket\n          href = href.slice(1);\n        } else {\n          href = href.slice(1, -1);\n        }\n      }\n\n      return outputLink(cap, {\n        href: href ? href.replace(this.rules.inline._escapes, '$1') : href,\n        title: title ? title.replace(this.rules.inline._escapes, '$1') : title\n      }, cap[0], this.lexer);\n    }\n  }\n\n  reflink(src, links) {\n    let cap;\n\n    if ((cap = this.rules.inline.reflink.exec(src)) || (cap = this.rules.inline.nolink.exec(src))) {\n      let link = (cap[2] || cap[1]).replace(/\\s+/g, ' ');\n      link = links[link.toLowerCase()];\n\n      if (!link || !link.href) {\n        const text = cap[0].charAt(0);\n        return {\n          type: 'text',\n          raw: text,\n          text\n        };\n      }\n\n      return outputLink(cap, link, cap[0], this.lexer);\n    }\n  }\n\n  emStrong(src, maskedSrc, prevChar = '') {\n    let match = this.rules.inline.emStrong.lDelim.exec(src);\n    if (!match) return; // _ can't be between two alphanumerics. \\p{L}\\p{N} includes non-english alphabet/numbers as well\n\n    if (match[3] && prevChar.match(/[\\p{L}\\p{N}]/u)) return;\n    const nextChar = match[1] || match[2] || '';\n\n    if (!nextChar || nextChar && (prevChar === '' || this.rules.inline.punctuation.exec(prevChar))) {\n      const lLength = match[0].length - 1;\n      let rDelim,\n          rLength,\n          delimTotal = lLength,\n          midDelimTotal = 0;\n      const endReg = match[0][0] === '*' ? this.rules.inline.emStrong.rDelimAst : this.rules.inline.emStrong.rDelimUnd;\n      endReg.lastIndex = 0; // Clip maskedSrc to same section of string as src (move to lexer?)\n\n      maskedSrc = maskedSrc.slice(-1 * src.length + lLength);\n\n      while ((match = endReg.exec(maskedSrc)) != null) {\n        rDelim = match[1] || match[2] || match[3] || match[4] || match[5] || match[6];\n        if (!rDelim) continue; // skip single * in __abc*abc__\n\n        rLength = rDelim.length;\n\n        if (match[3] || match[4]) {\n          // found another Left Delim\n          delimTotal += rLength;\n          continue;\n        } else if (match[5] || match[6]) {\n          // either Left or Right Delim\n          if (lLength % 3 && !((lLength + rLength) % 3)) {\n            midDelimTotal += rLength;\n            continue; // CommonMark Emphasis Rules 9-10\n          }\n        }\n\n        delimTotal -= rLength;\n        if (delimTotal > 0) continue; // Haven't found enough closing delimiters\n        // Remove extra characters. *a*** -> *a*\n\n        rLength = Math.min(rLength, rLength + delimTotal + midDelimTotal); // Create `em` if smallest delimiter has odd char count. *a***\n\n        if (Math.min(lLength, rLength) % 2) {\n          const text = src.slice(1, lLength + match.index + rLength);\n          return {\n            type: 'em',\n            raw: src.slice(0, lLength + match.index + rLength + 1),\n            text,\n            tokens: this.lexer.inlineTokens(text, [])\n          };\n        } // Create 'strong' if smallest delimiter has even char count. **a***\n\n\n        const text = src.slice(2, lLength + match.index + rLength - 1);\n        return {\n          type: 'strong',\n          raw: src.slice(0, lLength + match.index + rLength + 1),\n          text,\n          tokens: this.lexer.inlineTokens(text, [])\n        };\n      }\n    }\n  }\n\n  codespan(src) {\n    const cap = this.rules.inline.code.exec(src);\n\n    if (cap) {\n      let text = cap[2].replace(/\\n/g, ' ');\n      const hasNonSpaceChars = /[^ ]/.test(text);\n      const hasSpaceCharsOnBothEnds = /^ /.test(text) && / $/.test(text);\n\n      if (hasNonSpaceChars && hasSpaceCharsOnBothEnds) {\n        text = text.substring(1, text.length - 1);\n      }\n\n      text = escape(text, true);\n      return {\n        type: 'codespan',\n        raw: cap[0],\n        text\n      };\n    }\n  }\n\n  br(src) {\n    const cap = this.rules.inline.br.exec(src);\n\n    if (cap) {\n      return {\n        type: 'br',\n        raw: cap[0]\n      };\n    }\n  }\n\n  del(src) {\n    const cap = this.rules.inline.del.exec(src);\n\n    if (cap) {\n      return {\n        type: 'del',\n        raw: cap[0],\n        text: cap[2],\n        tokens: this.lexer.inlineTokens(cap[2], [])\n      };\n    }\n  }\n\n  autolink(src, mangle) {\n    const cap = this.rules.inline.autolink.exec(src);\n\n    if (cap) {\n      let text, href;\n\n      if (cap[2] === '@') {\n        text = escape(this.options.mangle ? mangle(cap[1]) : cap[1]);\n        href = 'mailto:' + text;\n      } else {\n        text = escape(cap[1]);\n        href = text;\n      }\n\n      return {\n        type: 'link',\n        raw: cap[0],\n        text,\n        href,\n        tokens: [{\n          type: 'text',\n          raw: text,\n          text\n        }]\n      };\n    }\n  }\n\n  url(src, mangle) {\n    let cap;\n\n    if (cap = this.rules.inline.url.exec(src)) {\n      let text, href;\n\n      if (cap[2] === '@') {\n        text = escape(this.options.mangle ? mangle(cap[0]) : cap[0]);\n        href = 'mailto:' + text;\n      } else {\n        // do extended autolink path validation\n        let prevCapZero;\n\n        do {\n          prevCapZero = cap[0];\n          cap[0] = this.rules.inline._backpedal.exec(cap[0])[0];\n        } while (prevCapZero !== cap[0]);\n\n        text = escape(cap[0]);\n\n        if (cap[1] === 'www.') {\n          href = 'http://' + text;\n        } else {\n          href = text;\n        }\n      }\n\n      return {\n        type: 'link',\n        raw: cap[0],\n        text,\n        href,\n        tokens: [{\n          type: 'text',\n          raw: text,\n          text\n        }]\n      };\n    }\n  }\n\n  inlineText(src, smartypants) {\n    const cap = this.rules.inline.text.exec(src);\n\n    if (cap) {\n      let text;\n\n      if (this.lexer.state.inRawBlock) {\n        text = this.options.sanitize ? this.options.sanitizer ? this.options.sanitizer(cap[0]) : escape(cap[0]) : cap[0];\n      } else {\n        text = escape(this.options.smartypants ? smartypants(cap[0]) : cap[0]);\n      }\n\n      return {\n        type: 'text',\n        raw: cap[0],\n        text\n      };\n    }\n  }\n\n}\n/**\n * Block-Level Grammar\n */\n\n\nconst block = {\n  newline: /^(?: *(?:\\n|$))+/,\n  code: /^( {4}[^\\n]+(?:\\n(?: *(?:\\n|$))*)?)+/,\n  fences: /^ {0,3}(`{3,}(?=[^`\\n]*\\n)|~{3,})([^\\n]*)\\n(?:|([\\s\\S]*?)\\n)(?: {0,3}\\1[~`]* *(?=\\n|$)|$)/,\n  hr: /^ {0,3}((?:- *){3,}|(?:_ *){3,}|(?:\\* *){3,})(?:\\n+|$)/,\n  heading: /^ {0,3}(#{1,6})(?=\\s|$)(.*)(?:\\n+|$)/,\n  blockquote: /^( {0,3}> ?(paragraph|[^\\n]*)(?:\\n|$))+/,\n  list: /^( {0,3}bull)( [^\\n]+?)?(?:\\n|$)/,\n  html: '^ {0,3}(?:' // optional indentation\n  + '<(script|pre|style|textarea)[\\\\s>][\\\\s\\\\S]*?(?:</\\\\1>[^\\\\n]*\\\\n+|$)' // (1)\n  + '|comment[^\\\\n]*(\\\\n+|$)' // (2)\n  + '|<\\\\?[\\\\s\\\\S]*?(?:\\\\?>\\\\n*|$)' // (3)\n  + '|<![A-Z][\\\\s\\\\S]*?(?:>\\\\n*|$)' // (4)\n  + '|<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?(?:\\\\]\\\\]>\\\\n*|$)' // (5)\n  + '|</?(tag)(?: +|\\\\n|/?>)[\\\\s\\\\S]*?(?:(?:\\\\n *)+\\\\n|$)' // (6)\n  + '|<(?!script|pre|style|textarea)([a-z][\\\\w-]*)(?:attribute)*? */?>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n *)+\\\\n|$)' // (7) open tag\n  + '|</(?!script|pre|style|textarea)[a-z][\\\\w-]*\\\\s*>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n *)+\\\\n|$)' // (7) closing tag\n  + ')',\n  def: /^ {0,3}\\[(label)\\]: *(?:\\n *)?<?([^\\s>]+)>?(?:(?: +(?:\\n *)?| *\\n *)(title))? *(?:\\n+|$)/,\n  table: noopTest,\n  lheading: /^([^\\n]+)\\n {0,3}(=+|-+) *(?:\\n+|$)/,\n  // regex template, placeholders will be replaced according to different paragraph\n  // interruption rules of commonmark and the original markdown spec:\n  _paragraph: /^([^\\n]+(?:\\n(?!hr|heading|lheading|blockquote|fences|list|html|table| +\\n)[^\\n]+)*)/,\n  text: /^[^\\n]+/\n};\nblock._label = /(?!\\s*\\])(?:\\\\.|[^\\[\\]\\\\])+/;\nblock._title = /(?:\"(?:\\\\\"?|[^\"\\\\])*\"|'[^'\\n]*(?:\\n[^'\\n]+)*\\n?'|\\([^()]*\\))/;\nblock.def = edit(block.def).replace('label', block._label).replace('title', block._title).getRegex();\nblock.bullet = /(?:[*+-]|\\d{1,9}[.)])/;\nblock.listItemStart = edit(/^( *)(bull) */).replace('bull', block.bullet).getRegex();\nblock.list = edit(block.list).replace(/bull/g, block.bullet).replace('hr', '\\\\n+(?=\\\\1?(?:(?:- *){3,}|(?:_ *){3,}|(?:\\\\* *){3,})(?:\\\\n+|$))').replace('def', '\\\\n+(?=' + block.def.source + ')').getRegex();\nblock._tag = 'address|article|aside|base|basefont|blockquote|body|caption' + '|center|col|colgroup|dd|details|dialog|dir|div|dl|dt|fieldset|figcaption' + '|figure|footer|form|frame|frameset|h[1-6]|head|header|hr|html|iframe' + '|legend|li|link|main|menu|menuitem|meta|nav|noframes|ol|optgroup|option' + '|p|param|section|source|summary|table|tbody|td|tfoot|th|thead|title|tr' + '|track|ul';\nblock._comment = /<!--(?!-?>)[\\s\\S]*?(?:-->|$)/;\nblock.html = edit(block.html, 'i').replace('comment', block._comment).replace('tag', block._tag).replace('attribute', / +[a-zA-Z:_][\\w.:-]*(?: *= *\"[^\"\\n]*\"| *= *'[^'\\n]*'| *= *[^\\s\"'=<>`]+)?/).getRegex();\nblock.paragraph = edit(block._paragraph).replace('hr', block.hr).replace('heading', ' {0,3}#{1,6} ').replace('|lheading', '') // setex headings don't interrupt commonmark paragraphs\n.replace('|table', '').replace('blockquote', ' {0,3}>').replace('fences', ' {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n').replace('list', ' {0,3}(?:[*+-]|1[.)]) ') // only lists starting from 1 can interrupt\n.replace('html', '</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)').replace('tag', block._tag) // pars can be interrupted by type (6) html blocks\n.getRegex();\nblock.blockquote = edit(block.blockquote).replace('paragraph', block.paragraph).getRegex();\n/**\n * Normal Block Grammar\n */\n\nblock.normal = merge({}, block);\n/**\n * GFM Block Grammar\n */\n\nblock.gfm = merge({}, block.normal, {\n  table: '^ *([^\\\\n ].*\\\\|.*)\\\\n' // Header\n  + ' {0,3}(?:\\\\| *)?(:?-+:? *(?:\\\\| *:?-+:? *)*)(?:\\\\| *)?' // Align\n  + '(?:\\\\n((?:(?! *\\\\n|hr|heading|blockquote|code|fences|list|html).*(?:\\\\n|$))*)\\\\n*|$)' // Cells\n\n});\nblock.gfm.table = edit(block.gfm.table).replace('hr', block.hr).replace('heading', ' {0,3}#{1,6} ').replace('blockquote', ' {0,3}>').replace('code', ' {4}[^\\\\n]').replace('fences', ' {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n').replace('list', ' {0,3}(?:[*+-]|1[.)]) ') // only lists starting from 1 can interrupt\n.replace('html', '</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)').replace('tag', block._tag) // tables can be interrupted by type (6) html blocks\n.getRegex();\nblock.gfm.paragraph = edit(block._paragraph).replace('hr', block.hr).replace('heading', ' {0,3}#{1,6} ').replace('|lheading', '') // setex headings don't interrupt commonmark paragraphs\n.replace('table', block.gfm.table) // interrupt paragraphs with table\n.replace('blockquote', ' {0,3}>').replace('fences', ' {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n').replace('list', ' {0,3}(?:[*+-]|1[.)]) ') // only lists starting from 1 can interrupt\n.replace('html', '</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)').replace('tag', block._tag) // pars can be interrupted by type (6) html blocks\n.getRegex();\n/**\n * Pedantic grammar (original John Gruber's loose markdown specification)\n */\n\nblock.pedantic = merge({}, block.normal, {\n  html: edit('^ *(?:comment *(?:\\\\n|\\\\s*$)' + '|<(tag)[\\\\s\\\\S]+?</\\\\1> *(?:\\\\n{2,}|\\\\s*$)' // closed tag\n  + '|<tag(?:\"[^\"]*\"|\\'[^\\']*\\'|\\\\s[^\\'\"/>\\\\s]*)*?/?> *(?:\\\\n{2,}|\\\\s*$))').replace('comment', block._comment).replace(/tag/g, '(?!(?:' + 'a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub' + '|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)' + '\\\\b)\\\\w+(?!:|[^\\\\w\\\\s@]*@)\\\\b').getRegex(),\n  def: /^ *\\[([^\\]]+)\\]: *<?([^\\s>]+)>?(?: +([\"(][^\\n]+[\")]))? *(?:\\n+|$)/,\n  heading: /^(#{1,6})(.*)(?:\\n+|$)/,\n  fences: noopTest,\n  // fences not supported\n  paragraph: edit(block.normal._paragraph).replace('hr', block.hr).replace('heading', ' *#{1,6} *[^\\n]').replace('lheading', block.lheading).replace('blockquote', ' {0,3}>').replace('|fences', '').replace('|list', '').replace('|html', '').getRegex()\n});\n/**\n * Inline-Level Grammar\n */\n\nconst inline = {\n  escape: /^\\\\([!\"#$%&'()*+,\\-./:;<=>?@\\[\\]\\\\^_`{|}~])/,\n  autolink: /^<(scheme:[^\\s\\x00-\\x1f<>]*|email)>/,\n  url: noopTest,\n  tag: '^comment' + '|^</[a-zA-Z][\\\\w:-]*\\\\s*>' // self-closing tag\n  + '|^<[a-zA-Z][\\\\w-]*(?:attribute)*?\\\\s*/?>' // open tag\n  + '|^<\\\\?[\\\\s\\\\S]*?\\\\?>' // processing instruction, e.g. <?php ?>\n  + '|^<![a-zA-Z]+\\\\s[\\\\s\\\\S]*?>' // declaration, e.g. <!DOCTYPE html>\n  + '|^<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?\\\\]\\\\]>',\n  // CDATA section\n  link: /^!?\\[(label)\\]\\(\\s*(href)(?:\\s+(title))?\\s*\\)/,\n  reflink: /^!?\\[(label)\\]\\[(ref)\\]/,\n  nolink: /^!?\\[(ref)\\](?:\\[\\])?/,\n  reflinkSearch: 'reflink|nolink(?!\\\\()',\n  emStrong: {\n    lDelim: /^(?:\\*+(?:([punct_])|[^\\s*]))|^_+(?:([punct*])|([^\\s_]))/,\n    //        (1) and (2) can only be a Right Delimiter. (3) and (4) can only be Left.  (5) and (6) can be either Left or Right.\n    //        () Skip orphan delim inside strong    (1) #***                (2) a***#, a***                   (3) #***a, ***a                 (4) ***#              (5) #***#                 (6) a***a\n    rDelimAst: /^[^_*]*?\\_\\_[^_*]*?\\*[^_*]*?(?=\\_\\_)|[punct_](\\*+)(?=[\\s]|$)|[^punct*_\\s](\\*+)(?=[punct_\\s]|$)|[punct_\\s](\\*+)(?=[^punct*_\\s])|[\\s](\\*+)(?=[punct_])|[punct_](\\*+)(?=[punct_])|[^punct*_\\s](\\*+)(?=[^punct*_\\s])/,\n    rDelimUnd: /^[^_*]*?\\*\\*[^_*]*?\\_[^_*]*?(?=\\*\\*)|[punct*](\\_+)(?=[\\s]|$)|[^punct*_\\s](\\_+)(?=[punct*\\s]|$)|[punct*\\s](\\_+)(?=[^punct*_\\s])|[\\s](\\_+)(?=[punct*])|[punct*](\\_+)(?=[punct*])/ // ^- Not allowed for _\n\n  },\n  code: /^(`+)([^`]|[^`][\\s\\S]*?[^`])\\1(?!`)/,\n  br: /^( {2,}|\\\\)\\n(?!\\s*$)/,\n  del: noopTest,\n  text: /^(`+|[^`])(?:(?= {2,}\\n)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*_]|\\b_|$)|[^ ](?= {2,}\\n)))/,\n  punctuation: /^([\\spunctuation])/\n}; // list of punctuation marks from CommonMark spec\n// without * and _ to handle the different emphasis markers * and _\n\ninline._punctuation = '!\"#$%&\\'()+\\\\-.,/:;<=>?@\\\\[\\\\]`^{|}~';\ninline.punctuation = edit(inline.punctuation).replace(/punctuation/g, inline._punctuation).getRegex(); // sequences em should skip over [title](link), `code`, <html>\n\ninline.blockSkip = /\\[[^\\]]*?\\]\\([^\\)]*?\\)|`[^`]*?`|<[^>]*?>/g;\ninline.escapedEmSt = /\\\\\\*|\\\\_/g;\ninline._comment = edit(block._comment).replace('(?:-->|$)', '-->').getRegex();\ninline.emStrong.lDelim = edit(inline.emStrong.lDelim).replace(/punct/g, inline._punctuation).getRegex();\ninline.emStrong.rDelimAst = edit(inline.emStrong.rDelimAst, 'g').replace(/punct/g, inline._punctuation).getRegex();\ninline.emStrong.rDelimUnd = edit(inline.emStrong.rDelimUnd, 'g').replace(/punct/g, inline._punctuation).getRegex();\ninline._escapes = /\\\\([!\"#$%&'()*+,\\-./:;<=>?@\\[\\]\\\\^_`{|}~])/g;\ninline._scheme = /[a-zA-Z][a-zA-Z0-9+.-]{1,31}/;\ninline._email = /[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+(@)[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)+(?![-_])/;\ninline.autolink = edit(inline.autolink).replace('scheme', inline._scheme).replace('email', inline._email).getRegex();\ninline._attribute = /\\s+[a-zA-Z:_][\\w.:-]*(?:\\s*=\\s*\"[^\"]*\"|\\s*=\\s*'[^']*'|\\s*=\\s*[^\\s\"'=<>`]+)?/;\ninline.tag = edit(inline.tag).replace('comment', inline._comment).replace('attribute', inline._attribute).getRegex();\ninline._label = /(?:\\[(?:\\\\.|[^\\[\\]\\\\])*\\]|\\\\.|`[^`]*`|[^\\[\\]\\\\`])*?/;\ninline._href = /<(?:\\\\.|[^\\n<>\\\\])+>|[^\\s\\x00-\\x1f]*/;\ninline._title = /\"(?:\\\\\"?|[^\"\\\\])*\"|'(?:\\\\'?|[^'\\\\])*'|\\((?:\\\\\\)?|[^)\\\\])*\\)/;\ninline.link = edit(inline.link).replace('label', inline._label).replace('href', inline._href).replace('title', inline._title).getRegex();\ninline.reflink = edit(inline.reflink).replace('label', inline._label).replace('ref', block._label).getRegex();\ninline.nolink = edit(inline.nolink).replace('ref', block._label).getRegex();\ninline.reflinkSearch = edit(inline.reflinkSearch, 'g').replace('reflink', inline.reflink).replace('nolink', inline.nolink).getRegex();\n/**\n * Normal Inline Grammar\n */\n\ninline.normal = merge({}, inline);\n/**\n * Pedantic Inline Grammar\n */\n\ninline.pedantic = merge({}, inline.normal, {\n  strong: {\n    start: /^__|\\*\\*/,\n    middle: /^__(?=\\S)([\\s\\S]*?\\S)__(?!_)|^\\*\\*(?=\\S)([\\s\\S]*?\\S)\\*\\*(?!\\*)/,\n    endAst: /\\*\\*(?!\\*)/g,\n    endUnd: /__(?!_)/g\n  },\n  em: {\n    start: /^_|\\*/,\n    middle: /^()\\*(?=\\S)([\\s\\S]*?\\S)\\*(?!\\*)|^_(?=\\S)([\\s\\S]*?\\S)_(?!_)/,\n    endAst: /\\*(?!\\*)/g,\n    endUnd: /_(?!_)/g\n  },\n  link: edit(/^!?\\[(label)\\]\\((.*?)\\)/).replace('label', inline._label).getRegex(),\n  reflink: edit(/^!?\\[(label)\\]\\s*\\[([^\\]]*)\\]/).replace('label', inline._label).getRegex()\n});\n/**\n * GFM Inline Grammar\n */\n\ninline.gfm = merge({}, inline.normal, {\n  escape: edit(inline.escape).replace('])', '~|])').getRegex(),\n  _extended_email: /[A-Za-z0-9._+-]+(@)[a-zA-Z0-9-_]+(?:\\.[a-zA-Z0-9-_]*[a-zA-Z0-9])+(?![-_])/,\n  url: /^((?:ftp|https?):\\/\\/|www\\.)(?:[a-zA-Z0-9\\-]+\\.?)+[^\\s<]*|^email/,\n  _backpedal: /(?:[^?!.,:;*_~()&]+|\\([^)]*\\)|&(?![a-zA-Z0-9]+;$)|[?!.,:;*_~)]+(?!$))+/,\n  del: /^(~~?)(?=[^\\s~])([\\s\\S]*?[^\\s~])\\1(?=[^~]|$)/,\n  text: /^([`~]+|[^`~])(?:(?= {2,}\\n)|(?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*~_]|\\b_|https?:\\/\\/|ftp:\\/\\/|www\\.|$)|[^ ](?= {2,}\\n)|[^a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-](?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)))/\n});\ninline.gfm.url = edit(inline.gfm.url, 'i').replace('email', inline.gfm._extended_email).getRegex();\n/**\n * GFM + Line Breaks Inline Grammar\n */\n\ninline.breaks = merge({}, inline.gfm, {\n  br: edit(inline.br).replace('{2,}', '*').getRegex(),\n  text: edit(inline.gfm.text).replace('\\\\b_', '\\\\b_| {2,}\\\\n').replace(/\\{2,\\}/g, '*').getRegex()\n});\n/**\n * smartypants text replacement\n */\n\nfunction smartypants(text) {\n  return text // em-dashes\n  .replace(/---/g, '\\u2014') // en-dashes\n  .replace(/--/g, '\\u2013') // opening singles\n  .replace(/(^|[-\\u2014/(\\[{\"\\s])'/g, '$1\\u2018') // closing singles & apostrophes\n  .replace(/'/g, '\\u2019') // opening doubles\n  .replace(/(^|[-\\u2014/(\\[{\\u2018\\s])\"/g, '$1\\u201c') // closing doubles\n  .replace(/\"/g, '\\u201d') // ellipses\n  .replace(/\\.{3}/g, '\\u2026');\n}\n/**\n * mangle email addresses\n */\n\n\nfunction mangle(text) {\n  let out = '',\n      i,\n      ch;\n  const l = text.length;\n\n  for (i = 0; i < l; i++) {\n    ch = text.charCodeAt(i);\n\n    if (Math.random() > 0.5) {\n      ch = 'x' + ch.toString(16);\n    }\n\n    out += '&#' + ch + ';';\n  }\n\n  return out;\n}\n/**\n * Block Lexer\n */\n\n\nclass Lexer {\n  constructor(options) {\n    this.tokens = [];\n    this.tokens.links = Object.create(null);\n    this.options = options || defaults;\n    this.options.tokenizer = this.options.tokenizer || new Tokenizer();\n    this.tokenizer = this.options.tokenizer;\n    this.tokenizer.options = this.options;\n    this.tokenizer.lexer = this;\n    this.inlineQueue = [];\n    this.state = {\n      inLink: false,\n      inRawBlock: false,\n      top: true\n    };\n    const rules = {\n      block: block.normal,\n      inline: inline.normal\n    };\n\n    if (this.options.pedantic) {\n      rules.block = block.pedantic;\n      rules.inline = inline.pedantic;\n    } else if (this.options.gfm) {\n      rules.block = block.gfm;\n\n      if (this.options.breaks) {\n        rules.inline = inline.breaks;\n      } else {\n        rules.inline = inline.gfm;\n      }\n    }\n\n    this.tokenizer.rules = rules;\n  }\n  /**\n   * Expose Rules\n   */\n\n\n  static get rules() {\n    return {\n      block,\n      inline\n    };\n  }\n  /**\n   * Static Lex Method\n   */\n\n\n  static lex(src, options) {\n    const lexer = new Lexer(options);\n    return lexer.lex(src);\n  }\n  /**\n   * Static Lex Inline Method\n   */\n\n\n  static lexInline(src, options) {\n    const lexer = new Lexer(options);\n    return lexer.inlineTokens(src);\n  }\n  /**\n   * Preprocessing\n   */\n\n\n  lex(src) {\n    src = src.replace(/\\r\\n|\\r/g, '\\n').replace(/\\t/g, '    ');\n    this.blockTokens(src, this.tokens);\n    let next;\n\n    while (next = this.inlineQueue.shift()) {\n      this.inlineTokens(next.src, next.tokens);\n    }\n\n    return this.tokens;\n  }\n  /**\n   * Lexing\n   */\n\n\n  blockTokens(src, tokens = []) {\n    if (this.options.pedantic) {\n      src = src.replace(/^ +$/gm, '');\n    }\n\n    let token, lastToken, cutSrc, lastParagraphClipped;\n\n    while (src) {\n      if (this.options.extensions && this.options.extensions.block && this.options.extensions.block.some(extTokenizer => {\n        if (token = extTokenizer.call({\n          lexer: this\n        }, src, tokens)) {\n          src = src.substring(token.raw.length);\n          tokens.push(token);\n          return true;\n        }\n\n        return false;\n      })) {\n        continue;\n      } // newline\n\n\n      if (token = this.tokenizer.space(src)) {\n        src = src.substring(token.raw.length);\n\n        if (token.raw.length === 1 && tokens.length > 0) {\n          // if there's a single \\n as a spacer, it's terminating the last line,\n          // so move it there so that we don't get unecessary paragraph tags\n          tokens[tokens.length - 1].raw += '\\n';\n        } else {\n          tokens.push(token);\n        }\n\n        continue;\n      } // code\n\n\n      if (token = this.tokenizer.code(src)) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1]; // An indented code block cannot interrupt a paragraph.\n\n        if (lastToken && (lastToken.type === 'paragraph' || lastToken.type === 'text')) {\n          lastToken.raw += '\\n' + token.raw;\n          lastToken.text += '\\n' + token.text;\n          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n\n        continue;\n      } // fences\n\n\n      if (token = this.tokenizer.fences(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      } // heading\n\n\n      if (token = this.tokenizer.heading(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      } // hr\n\n\n      if (token = this.tokenizer.hr(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      } // blockquote\n\n\n      if (token = this.tokenizer.blockquote(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      } // list\n\n\n      if (token = this.tokenizer.list(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      } // html\n\n\n      if (token = this.tokenizer.html(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      } // def\n\n\n      if (token = this.tokenizer.def(src)) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n\n        if (lastToken && (lastToken.type === 'paragraph' || lastToken.type === 'text')) {\n          lastToken.raw += '\\n' + token.raw;\n          lastToken.text += '\\n' + token.raw;\n          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n        } else if (!this.tokens.links[token.tag]) {\n          this.tokens.links[token.tag] = {\n            href: token.href,\n            title: token.title\n          };\n        }\n\n        continue;\n      } // table (gfm)\n\n\n      if (token = this.tokenizer.table(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      } // lheading\n\n\n      if (token = this.tokenizer.lheading(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      } // top-level paragraph\n      // prevent paragraph consuming extensions by clipping 'src' to extension start\n\n\n      cutSrc = src;\n\n      if (this.options.extensions && this.options.extensions.startBlock) {\n        let startIndex = Infinity;\n        const tempSrc = src.slice(1);\n        let tempStart;\n        this.options.extensions.startBlock.forEach(function (getStartIndex) {\n          tempStart = getStartIndex.call({\n            lexer: this\n          }, tempSrc);\n\n          if (typeof tempStart === 'number' && tempStart >= 0) {\n            startIndex = Math.min(startIndex, tempStart);\n          }\n        });\n\n        if (startIndex < Infinity && startIndex >= 0) {\n          cutSrc = src.substring(0, startIndex + 1);\n        }\n      }\n\n      if (this.state.top && (token = this.tokenizer.paragraph(cutSrc))) {\n        lastToken = tokens[tokens.length - 1];\n\n        if (lastParagraphClipped && lastToken.type === 'paragraph') {\n          lastToken.raw += '\\n' + token.raw;\n          lastToken.text += '\\n' + token.text;\n          this.inlineQueue.pop();\n          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n\n        lastParagraphClipped = cutSrc.length !== src.length;\n        src = src.substring(token.raw.length);\n        continue;\n      } // text\n\n\n      if (token = this.tokenizer.text(src)) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n\n        if (lastToken && lastToken.type === 'text') {\n          lastToken.raw += '\\n' + token.raw;\n          lastToken.text += '\\n' + token.text;\n          this.inlineQueue.pop();\n          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n\n        continue;\n      }\n\n      if (src) {\n        const errMsg = 'Infinite loop on byte: ' + src.charCodeAt(0);\n\n        if (this.options.silent) {\n          console.error(errMsg);\n          break;\n        } else {\n          throw new Error(errMsg);\n        }\n      }\n    }\n\n    this.state.top = true;\n    return tokens;\n  }\n\n  inline(src, tokens) {\n    this.inlineQueue.push({\n      src,\n      tokens\n    });\n  }\n  /**\n   * Lexing/Compiling\n   */\n\n\n  inlineTokens(src, tokens = []) {\n    let token, lastToken, cutSrc; // String with links masked to avoid interference with em and strong\n\n    let maskedSrc = src;\n    let match;\n    let keepPrevChar, prevChar; // Mask out reflinks\n\n    if (this.tokens.links) {\n      const links = Object.keys(this.tokens.links);\n\n      if (links.length > 0) {\n        while ((match = this.tokenizer.rules.inline.reflinkSearch.exec(maskedSrc)) != null) {\n          if (links.includes(match[0].slice(match[0].lastIndexOf('[') + 1, -1))) {\n            maskedSrc = maskedSrc.slice(0, match.index) + '[' + repeatString('a', match[0].length - 2) + ']' + maskedSrc.slice(this.tokenizer.rules.inline.reflinkSearch.lastIndex);\n          }\n        }\n      }\n    } // Mask out other blocks\n\n\n    while ((match = this.tokenizer.rules.inline.blockSkip.exec(maskedSrc)) != null) {\n      maskedSrc = maskedSrc.slice(0, match.index) + '[' + repeatString('a', match[0].length - 2) + ']' + maskedSrc.slice(this.tokenizer.rules.inline.blockSkip.lastIndex);\n    } // Mask out escaped em & strong delimiters\n\n\n    while ((match = this.tokenizer.rules.inline.escapedEmSt.exec(maskedSrc)) != null) {\n      maskedSrc = maskedSrc.slice(0, match.index) + '++' + maskedSrc.slice(this.tokenizer.rules.inline.escapedEmSt.lastIndex);\n    }\n\n    while (src) {\n      if (!keepPrevChar) {\n        prevChar = '';\n      }\n\n      keepPrevChar = false; // extensions\n\n      if (this.options.extensions && this.options.extensions.inline && this.options.extensions.inline.some(extTokenizer => {\n        if (token = extTokenizer.call({\n          lexer: this\n        }, src, tokens)) {\n          src = src.substring(token.raw.length);\n          tokens.push(token);\n          return true;\n        }\n\n        return false;\n      })) {\n        continue;\n      } // escape\n\n\n      if (token = this.tokenizer.escape(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      } // tag\n\n\n      if (token = this.tokenizer.tag(src)) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n\n        if (lastToken && token.type === 'text' && lastToken.type === 'text') {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n\n        continue;\n      } // link\n\n\n      if (token = this.tokenizer.link(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      } // reflink, nolink\n\n\n      if (token = this.tokenizer.reflink(src, this.tokens.links)) {\n        src = src.substring(token.raw.length);\n        lastToken = tokens[tokens.length - 1];\n\n        if (lastToken && token.type === 'text' && lastToken.type === 'text') {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n\n        continue;\n      } // em & strong\n\n\n      if (token = this.tokenizer.emStrong(src, maskedSrc, prevChar)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      } // code\n\n\n      if (token = this.tokenizer.codespan(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      } // br\n\n\n      if (token = this.tokenizer.br(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      } // del (gfm)\n\n\n      if (token = this.tokenizer.del(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      } // autolink\n\n\n      if (token = this.tokenizer.autolink(src, mangle)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      } // url (gfm)\n\n\n      if (!this.state.inLink && (token = this.tokenizer.url(src, mangle))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      } // text\n      // prevent inlineText consuming extensions by clipping 'src' to extension start\n\n\n      cutSrc = src;\n\n      if (this.options.extensions && this.options.extensions.startInline) {\n        let startIndex = Infinity;\n        const tempSrc = src.slice(1);\n        let tempStart;\n        this.options.extensions.startInline.forEach(function (getStartIndex) {\n          tempStart = getStartIndex.call({\n            lexer: this\n          }, tempSrc);\n\n          if (typeof tempStart === 'number' && tempStart >= 0) {\n            startIndex = Math.min(startIndex, tempStart);\n          }\n        });\n\n        if (startIndex < Infinity && startIndex >= 0) {\n          cutSrc = src.substring(0, startIndex + 1);\n        }\n      }\n\n      if (token = this.tokenizer.inlineText(cutSrc, smartypants)) {\n        src = src.substring(token.raw.length);\n\n        if (token.raw.slice(-1) !== '_') {\n          // Track prevChar before string of ____ started\n          prevChar = token.raw.slice(-1);\n        }\n\n        keepPrevChar = true;\n        lastToken = tokens[tokens.length - 1];\n\n        if (lastToken && lastToken.type === 'text') {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n\n        continue;\n      }\n\n      if (src) {\n        const errMsg = 'Infinite loop on byte: ' + src.charCodeAt(0);\n\n        if (this.options.silent) {\n          console.error(errMsg);\n          break;\n        } else {\n          throw new Error(errMsg);\n        }\n      }\n    }\n\n    return tokens;\n  }\n\n}\n/**\n * Renderer\n */\n\n\nclass Renderer {\n  constructor(options) {\n    this.options = options || defaults;\n  }\n\n  code(code, infostring, escaped) {\n    const lang = (infostring || '').match(/\\S*/)[0];\n\n    if (this.options.highlight) {\n      const out = this.options.highlight(code, lang);\n\n      if (out != null && out !== code) {\n        escaped = true;\n        code = out;\n      }\n    }\n\n    code = code.replace(/\\n$/, '') + '\\n';\n\n    if (!lang) {\n      return '<pre><code>' + (escaped ? code : escape(code, true)) + '</code></pre>\\n';\n    }\n\n    return '<pre><code class=\"' + this.options.langPrefix + escape(lang, true) + '\">' + (escaped ? code : escape(code, true)) + '</code></pre>\\n';\n  }\n\n  blockquote(quote) {\n    return '<blockquote>\\n' + quote + '</blockquote>\\n';\n  }\n\n  html(html) {\n    return html;\n  }\n\n  heading(text, level, raw, slugger) {\n    if (this.options.headerIds) {\n      return '<h' + level + ' id=\"' + this.options.headerPrefix + slugger.slug(raw) + '\">' + text + '</h' + level + '>\\n';\n    } // ignore IDs\n\n\n    return '<h' + level + '>' + text + '</h' + level + '>\\n';\n  }\n\n  hr() {\n    return this.options.xhtml ? '<hr/>\\n' : '<hr>\\n';\n  }\n\n  list(body, ordered, start) {\n    const type = ordered ? 'ol' : 'ul',\n          startatt = ordered && start !== 1 ? ' start=\"' + start + '\"' : '';\n    return '<' + type + startatt + '>\\n' + body + '</' + type + '>\\n';\n  }\n\n  listitem(text) {\n    return '<li>' + text + '</li>\\n';\n  }\n\n  checkbox(checked) {\n    return '<input ' + (checked ? 'checked=\"\" ' : '') + 'disabled=\"\" type=\"checkbox\"' + (this.options.xhtml ? ' /' : '') + '> ';\n  }\n\n  paragraph(text) {\n    return '<p>' + text + '</p>\\n';\n  }\n\n  table(header, body) {\n    if (body) body = '<tbody>' + body + '</tbody>';\n    return '<table>\\n' + '<thead>\\n' + header + '</thead>\\n' + body + '</table>\\n';\n  }\n\n  tablerow(content) {\n    return '<tr>\\n' + content + '</tr>\\n';\n  }\n\n  tablecell(content, flags) {\n    const type = flags.header ? 'th' : 'td';\n    const tag = flags.align ? '<' + type + ' align=\"' + flags.align + '\">' : '<' + type + '>';\n    return tag + content + '</' + type + '>\\n';\n  } // span level renderer\n\n\n  strong(text) {\n    return '<strong>' + text + '</strong>';\n  }\n\n  em(text) {\n    return '<em>' + text + '</em>';\n  }\n\n  codespan(text) {\n    return '<code>' + text + '</code>';\n  }\n\n  br() {\n    return this.options.xhtml ? '<br/>' : '<br>';\n  }\n\n  del(text) {\n    return '<del>' + text + '</del>';\n  }\n\n  link(href, title, text) {\n    href = cleanUrl(this.options.sanitize, this.options.baseUrl, href);\n\n    if (href === null) {\n      return text;\n    }\n\n    let out = '<a href=\"' + escape(href) + '\"';\n\n    if (title) {\n      out += ' title=\"' + title + '\"';\n    }\n\n    out += '>' + text + '</a>';\n    return out;\n  }\n\n  image(href, title, text) {\n    href = cleanUrl(this.options.sanitize, this.options.baseUrl, href);\n\n    if (href === null) {\n      return text;\n    }\n\n    let out = '<img src=\"' + href + '\" alt=\"' + text + '\"';\n\n    if (title) {\n      out += ' title=\"' + title + '\"';\n    }\n\n    out += this.options.xhtml ? '/>' : '>';\n    return out;\n  }\n\n  text(text) {\n    return text;\n  }\n\n}\n/**\n * TextRenderer\n * returns only the textual part of the token\n */\n\n\nclass TextRenderer {\n  // no need for block level renderers\n  strong(text) {\n    return text;\n  }\n\n  em(text) {\n    return text;\n  }\n\n  codespan(text) {\n    return text;\n  }\n\n  del(text) {\n    return text;\n  }\n\n  html(text) {\n    return text;\n  }\n\n  text(text) {\n    return text;\n  }\n\n  link(href, title, text) {\n    return '' + text;\n  }\n\n  image(href, title, text) {\n    return '' + text;\n  }\n\n  br() {\n    return '';\n  }\n\n}\n/**\n * Slugger generates header id\n */\n\n\nclass Slugger {\n  constructor() {\n    this.seen = {};\n  }\n\n  serialize(value) {\n    return value.toLowerCase().trim() // remove html tags\n    .replace(/<[!\\/a-z].*?>/ig, '') // remove unwanted chars\n    .replace(/[\\u2000-\\u206F\\u2E00-\\u2E7F\\\\'!\"#$%&()*+,./:;<=>?@[\\]^`{|}~]/g, '').replace(/\\s/g, '-');\n  }\n  /**\n   * Finds the next safe (unique) slug to use\n   */\n\n\n  getNextSafeSlug(originalSlug, isDryRun) {\n    let slug = originalSlug;\n    let occurenceAccumulator = 0;\n\n    if (this.seen.hasOwnProperty(slug)) {\n      occurenceAccumulator = this.seen[originalSlug];\n\n      do {\n        occurenceAccumulator++;\n        slug = originalSlug + '-' + occurenceAccumulator;\n      } while (this.seen.hasOwnProperty(slug));\n    }\n\n    if (!isDryRun) {\n      this.seen[originalSlug] = occurenceAccumulator;\n      this.seen[slug] = 0;\n    }\n\n    return slug;\n  }\n  /**\n   * Convert string to unique id\n   * @param {object} options\n   * @param {boolean} options.dryrun Generates the next unique slug without updating the internal accumulator.\n   */\n\n\n  slug(value, options = {}) {\n    const slug = this.serialize(value);\n    return this.getNextSafeSlug(slug, options.dryrun);\n  }\n\n}\n/**\n * Parsing & Compiling\n */\n\n\nclass Parser {\n  constructor(options) {\n    this.options = options || defaults;\n    this.options.renderer = this.options.renderer || new Renderer();\n    this.renderer = this.options.renderer;\n    this.renderer.options = this.options;\n    this.textRenderer = new TextRenderer();\n    this.slugger = new Slugger();\n  }\n  /**\n   * Static Parse Method\n   */\n\n\n  static parse(tokens, options) {\n    const parser = new Parser(options);\n    return parser.parse(tokens);\n  }\n  /**\n   * Static Parse Inline Method\n   */\n\n\n  static parseInline(tokens, options) {\n    const parser = new Parser(options);\n    return parser.parseInline(tokens);\n  }\n  /**\n   * Parse Loop\n   */\n\n\n  parse(tokens, top = true) {\n    let out = '',\n        i,\n        j,\n        k,\n        l2,\n        l3,\n        row,\n        cell,\n        header,\n        body,\n        token,\n        ordered,\n        start,\n        loose,\n        itemBody,\n        item,\n        checked,\n        task,\n        checkbox,\n        ret;\n    const l = tokens.length;\n\n    for (i = 0; i < l; i++) {\n      token = tokens[i]; // Run any renderer extensions\n\n      if (this.options.extensions && this.options.extensions.renderers && this.options.extensions.renderers[token.type]) {\n        ret = this.options.extensions.renderers[token.type].call({\n          parser: this\n        }, token);\n\n        if (ret !== false || !['space', 'hr', 'heading', 'code', 'table', 'blockquote', 'list', 'html', 'paragraph', 'text'].includes(token.type)) {\n          out += ret || '';\n          continue;\n        }\n      }\n\n      switch (token.type) {\n        case 'space':\n          {\n            continue;\n          }\n\n        case 'hr':\n          {\n            out += this.renderer.hr();\n            continue;\n          }\n\n        case 'heading':\n          {\n            out += this.renderer.heading(this.parseInline(token.tokens), token.depth, unescape(this.parseInline(token.tokens, this.textRenderer)), this.slugger);\n            continue;\n          }\n\n        case 'code':\n          {\n            out += this.renderer.code(token.text, token.lang, token.escaped);\n            continue;\n          }\n\n        case 'table':\n          {\n            header = ''; // header\n\n            cell = '';\n            l2 = token.header.length;\n\n            for (j = 0; j < l2; j++) {\n              cell += this.renderer.tablecell(this.parseInline(token.header[j].tokens), {\n                header: true,\n                align: token.align[j]\n              });\n            }\n\n            header += this.renderer.tablerow(cell);\n            body = '';\n            l2 = token.rows.length;\n\n            for (j = 0; j < l2; j++) {\n              row = token.rows[j];\n              cell = '';\n              l3 = row.length;\n\n              for (k = 0; k < l3; k++) {\n                cell += this.renderer.tablecell(this.parseInline(row[k].tokens), {\n                  header: false,\n                  align: token.align[k]\n                });\n              }\n\n              body += this.renderer.tablerow(cell);\n            }\n\n            out += this.renderer.table(header, body);\n            continue;\n          }\n\n        case 'blockquote':\n          {\n            body = this.parse(token.tokens);\n            out += this.renderer.blockquote(body);\n            continue;\n          }\n\n        case 'list':\n          {\n            ordered = token.ordered;\n            start = token.start;\n            loose = token.loose;\n            l2 = token.items.length;\n            body = '';\n\n            for (j = 0; j < l2; j++) {\n              item = token.items[j];\n              checked = item.checked;\n              task = item.task;\n              itemBody = '';\n\n              if (item.task) {\n                checkbox = this.renderer.checkbox(checked);\n\n                if (loose) {\n                  if (item.tokens.length > 0 && item.tokens[0].type === 'paragraph') {\n                    item.tokens[0].text = checkbox + ' ' + item.tokens[0].text;\n\n                    if (item.tokens[0].tokens && item.tokens[0].tokens.length > 0 && item.tokens[0].tokens[0].type === 'text') {\n                      item.tokens[0].tokens[0].text = checkbox + ' ' + item.tokens[0].tokens[0].text;\n                    }\n                  } else {\n                    item.tokens.unshift({\n                      type: 'text',\n                      text: checkbox\n                    });\n                  }\n                } else {\n                  itemBody += checkbox;\n                }\n              }\n\n              itemBody += this.parse(item.tokens, loose);\n              body += this.renderer.listitem(itemBody, task, checked);\n            }\n\n            out += this.renderer.list(body, ordered, start);\n            continue;\n          }\n\n        case 'html':\n          {\n            // TODO parse inline content if parameter markdown=1\n            out += this.renderer.html(token.text);\n            continue;\n          }\n\n        case 'paragraph':\n          {\n            out += this.renderer.paragraph(this.parseInline(token.tokens));\n            continue;\n          }\n\n        case 'text':\n          {\n            body = token.tokens ? this.parseInline(token.tokens) : token.text;\n\n            while (i + 1 < l && tokens[i + 1].type === 'text') {\n              token = tokens[++i];\n              body += '\\n' + (token.tokens ? this.parseInline(token.tokens) : token.text);\n            }\n\n            out += top ? this.renderer.paragraph(body) : body;\n            continue;\n          }\n\n        default:\n          {\n            const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n\n            if (this.options.silent) {\n              console.error(errMsg);\n              return;\n            } else {\n              throw new Error(errMsg);\n            }\n          }\n      }\n    }\n\n    return out;\n  }\n  /**\n   * Parse Inline Tokens\n   */\n\n\n  parseInline(tokens, renderer) {\n    renderer = renderer || this.renderer;\n    let out = '',\n        i,\n        token,\n        ret;\n    const l = tokens.length;\n\n    for (i = 0; i < l; i++) {\n      token = tokens[i]; // Run any renderer extensions\n\n      if (this.options.extensions && this.options.extensions.renderers && this.options.extensions.renderers[token.type]) {\n        ret = this.options.extensions.renderers[token.type].call({\n          parser: this\n        }, token);\n\n        if (ret !== false || !['escape', 'html', 'link', 'image', 'strong', 'em', 'codespan', 'br', 'del', 'text'].includes(token.type)) {\n          out += ret || '';\n          continue;\n        }\n      }\n\n      switch (token.type) {\n        case 'escape':\n          {\n            out += renderer.text(token.text);\n            break;\n          }\n\n        case 'html':\n          {\n            out += renderer.html(token.text);\n            break;\n          }\n\n        case 'link':\n          {\n            out += renderer.link(token.href, token.title, this.parseInline(token.tokens, renderer));\n            break;\n          }\n\n        case 'image':\n          {\n            out += renderer.image(token.href, token.title, token.text);\n            break;\n          }\n\n        case 'strong':\n          {\n            out += renderer.strong(this.parseInline(token.tokens, renderer));\n            break;\n          }\n\n        case 'em':\n          {\n            out += renderer.em(this.parseInline(token.tokens, renderer));\n            break;\n          }\n\n        case 'codespan':\n          {\n            out += renderer.codespan(token.text);\n            break;\n          }\n\n        case 'br':\n          {\n            out += renderer.br();\n            break;\n          }\n\n        case 'del':\n          {\n            out += renderer.del(this.parseInline(token.tokens, renderer));\n            break;\n          }\n\n        case 'text':\n          {\n            out += renderer.text(token.text);\n            break;\n          }\n\n        default:\n          {\n            const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n\n            if (this.options.silent) {\n              console.error(errMsg);\n              return;\n            } else {\n              throw new Error(errMsg);\n            }\n          }\n      }\n    }\n\n    return out;\n  }\n\n}\n/**\n * Marked\n */\n\n\nfunction marked(src, opt, callback) {\n  // throw error in case of non string input\n  if (typeof src === 'undefined' || src === null) {\n    throw new Error('marked(): input parameter is undefined or null');\n  }\n\n  if (typeof src !== 'string') {\n    throw new Error('marked(): input parameter is of type ' + Object.prototype.toString.call(src) + ', string expected');\n  }\n\n  if (typeof opt === 'function') {\n    callback = opt;\n    opt = null;\n  }\n\n  opt = merge({}, marked.defaults, opt || {});\n  checkSanitizeDeprecation(opt);\n\n  if (callback) {\n    const highlight = opt.highlight;\n    let tokens;\n\n    try {\n      tokens = Lexer.lex(src, opt);\n    } catch (e) {\n      return callback(e);\n    }\n\n    const done = function (err) {\n      let out;\n\n      if (!err) {\n        try {\n          if (opt.walkTokens) {\n            marked.walkTokens(tokens, opt.walkTokens);\n          }\n\n          out = Parser.parse(tokens, opt);\n        } catch (e) {\n          err = e;\n        }\n      }\n\n      opt.highlight = highlight;\n      return err ? callback(err) : callback(null, out);\n    };\n\n    if (!highlight || highlight.length < 3) {\n      return done();\n    }\n\n    delete opt.highlight;\n    if (!tokens.length) return done();\n    let pending = 0;\n    marked.walkTokens(tokens, function (token) {\n      if (token.type === 'code') {\n        pending++;\n        setTimeout(() => {\n          highlight(token.text, token.lang, function (err, code) {\n            if (err) {\n              return done(err);\n            }\n\n            if (code != null && code !== token.text) {\n              token.text = code;\n              token.escaped = true;\n            }\n\n            pending--;\n\n            if (pending === 0) {\n              done();\n            }\n          });\n        }, 0);\n      }\n    });\n\n    if (pending === 0) {\n      done();\n    }\n\n    return;\n  }\n\n  try {\n    const tokens = Lexer.lex(src, opt);\n\n    if (opt.walkTokens) {\n      marked.walkTokens(tokens, opt.walkTokens);\n    }\n\n    return Parser.parse(tokens, opt);\n  } catch (e) {\n    e.message += '\\nPlease report this to https://github.com/markedjs/marked.';\n\n    if (opt.silent) {\n      return '<p>An error occurred:</p><pre>' + escape(e.message + '', true) + '</pre>';\n    }\n\n    throw e;\n  }\n}\n/**\n * Options\n */\n\n\nmarked.options = marked.setOptions = function (opt) {\n  merge(marked.defaults, opt);\n  changeDefaults(marked.defaults);\n  return marked;\n};\n\nmarked.getDefaults = getDefaults;\nmarked.defaults = defaults;\n/**\n * Use Extension\n */\n\nmarked.use = function (...args) {\n  const opts = merge({}, ...args);\n  const extensions = marked.defaults.extensions || {\n    renderers: {},\n    childTokens: {}\n  };\n  let hasExtensions;\n  args.forEach(pack => {\n    // ==-- Parse \"addon\" extensions --== //\n    if (pack.extensions) {\n      hasExtensions = true;\n      pack.extensions.forEach(ext => {\n        if (!ext.name) {\n          throw new Error('extension name required');\n        }\n\n        if (ext.renderer) {\n          // Renderer extensions\n          const prevRenderer = extensions.renderers ? extensions.renderers[ext.name] : null;\n\n          if (prevRenderer) {\n            // Replace extension with func to run new extension but fall back if false\n            extensions.renderers[ext.name] = function (...args) {\n              let ret = ext.renderer.apply(this, args);\n\n              if (ret === false) {\n                ret = prevRenderer.apply(this, args);\n              }\n\n              return ret;\n            };\n          } else {\n            extensions.renderers[ext.name] = ext.renderer;\n          }\n        }\n\n        if (ext.tokenizer) {\n          // Tokenizer Extensions\n          if (!ext.level || ext.level !== 'block' && ext.level !== 'inline') {\n            throw new Error(\"extension level must be 'block' or 'inline'\");\n          }\n\n          if (extensions[ext.level]) {\n            extensions[ext.level].unshift(ext.tokenizer);\n          } else {\n            extensions[ext.level] = [ext.tokenizer];\n          }\n\n          if (ext.start) {\n            // Function to check for start of token\n            if (ext.level === 'block') {\n              if (extensions.startBlock) {\n                extensions.startBlock.push(ext.start);\n              } else {\n                extensions.startBlock = [ext.start];\n              }\n            } else if (ext.level === 'inline') {\n              if (extensions.startInline) {\n                extensions.startInline.push(ext.start);\n              } else {\n                extensions.startInline = [ext.start];\n              }\n            }\n          }\n        }\n\n        if (ext.childTokens) {\n          // Child tokens to be visited by walkTokens\n          extensions.childTokens[ext.name] = ext.childTokens;\n        }\n      });\n    } // ==-- Parse \"overwrite\" extensions --== //\n\n\n    if (pack.renderer) {\n      const renderer = marked.defaults.renderer || new Renderer();\n\n      for (const prop in pack.renderer) {\n        const prevRenderer = renderer[prop]; // Replace renderer with func to run extension, but fall back if false\n\n        renderer[prop] = (...args) => {\n          let ret = pack.renderer[prop].apply(renderer, args);\n\n          if (ret === false) {\n            ret = prevRenderer.apply(renderer, args);\n          }\n\n          return ret;\n        };\n      }\n\n      opts.renderer = renderer;\n    }\n\n    if (pack.tokenizer) {\n      const tokenizer = marked.defaults.tokenizer || new Tokenizer();\n\n      for (const prop in pack.tokenizer) {\n        const prevTokenizer = tokenizer[prop]; // Replace tokenizer with func to run extension, but fall back if false\n\n        tokenizer[prop] = (...args) => {\n          let ret = pack.tokenizer[prop].apply(tokenizer, args);\n\n          if (ret === false) {\n            ret = prevTokenizer.apply(tokenizer, args);\n          }\n\n          return ret;\n        };\n      }\n\n      opts.tokenizer = tokenizer;\n    } // ==-- Parse WalkTokens extensions --== //\n\n\n    if (pack.walkTokens) {\n      const walkTokens = marked.defaults.walkTokens;\n\n      opts.walkTokens = function (token) {\n        pack.walkTokens.call(this, token);\n\n        if (walkTokens) {\n          walkTokens.call(this, token);\n        }\n      };\n    }\n\n    if (hasExtensions) {\n      opts.extensions = extensions;\n    }\n\n    marked.setOptions(opts);\n  });\n};\n/**\n * Run callback for every token\n */\n\n\nmarked.walkTokens = function (tokens, callback) {\n  for (const token of tokens) {\n    callback.call(marked, token);\n\n    switch (token.type) {\n      case 'table':\n        {\n          for (const cell of token.header) {\n            marked.walkTokens(cell.tokens, callback);\n          }\n\n          for (const row of token.rows) {\n            for (const cell of row) {\n              marked.walkTokens(cell.tokens, callback);\n            }\n          }\n\n          break;\n        }\n\n      case 'list':\n        {\n          marked.walkTokens(token.items, callback);\n          break;\n        }\n\n      default:\n        {\n          if (marked.defaults.extensions && marked.defaults.extensions.childTokens && marked.defaults.extensions.childTokens[token.type]) {\n            // Walk any extensions\n            marked.defaults.extensions.childTokens[token.type].forEach(function (childTokens) {\n              marked.walkTokens(token[childTokens], callback);\n            });\n          } else if (token.tokens) {\n            marked.walkTokens(token.tokens, callback);\n          }\n        }\n    }\n  }\n};\n/**\n * Parse Inline\n */\n\n\nmarked.parseInline = function (src, opt) {\n  // throw error in case of non string input\n  if (typeof src === 'undefined' || src === null) {\n    throw new Error('marked.parseInline(): input parameter is undefined or null');\n  }\n\n  if (typeof src !== 'string') {\n    throw new Error('marked.parseInline(): input parameter is of type ' + Object.prototype.toString.call(src) + ', string expected');\n  }\n\n  opt = merge({}, marked.defaults, opt || {});\n  checkSanitizeDeprecation(opt);\n\n  try {\n    const tokens = Lexer.lexInline(src, opt);\n\n    if (opt.walkTokens) {\n      marked.walkTokens(tokens, opt.walkTokens);\n    }\n\n    return Parser.parseInline(tokens, opt);\n  } catch (e) {\n    e.message += '\\nPlease report this to https://github.com/markedjs/marked.';\n\n    if (opt.silent) {\n      return '<p>An error occurred:</p><pre>' + escape(e.message + '', true) + '</pre>';\n    }\n\n    throw e;\n  }\n};\n/**\n * Expose\n */\n\n\nmarked.Parser = Parser;\nmarked.parser = Parser.parse;\nmarked.Renderer = Renderer;\nmarked.TextRenderer = TextRenderer;\nmarked.Lexer = Lexer;\nmarked.lexer = Lexer.lex;\nmarked.Tokenizer = Tokenizer;\nmarked.Slugger = Slugger;\nmarked.parse = marked;\nconst options = marked.options;\nconst setOptions = marked.setOptions;\nconst use = marked.use;\nconst walkTokens = marked.walkTokens;\nconst parseInline = marked.parseInline;\nconst parse = marked;\nconst parser = Parser.parse;\nconst lexer = Lexer.lex;\nexport { Lexer, Parser, Renderer, Slugger, TextRenderer, Tokenizer, defaults, getDefaults, lexer, marked, options, parse, parseInline, parser, setOptions, use, walkTokens };","map":null,"metadata":{},"sourceType":"module"}